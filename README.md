# üíª Laptop Price Predictor ‚Äî End-to-End ML Project with MLOps üöÄ

An end-to-end Machine Learning project to predict laptop prices based on hardware configurations like RAM, CPU, GPU, and more. This project is production-ready, fully integrated with **MongoDB Atlas**, **AWS S3**, **CI/CD pipeline via GitHub Actions**, **Docker**, and **FastAPI** for serving the model. Perfect example of how MLOps can take a data science model from notebook to a scalable, cloud-deployed app.

---

## üìÇ Project Structure

```

‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ components/              # All ML components (ingestion, validation, training, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ configuration/          # MongoDB and AWS configurations
‚îÇ   ‚îú‚îÄ‚îÄ entity/                 # Entity classes for configs and artifacts
‚îÇ   ‚îú‚îÄ‚îÄ exception/              # Custom exception handling
‚îÇ   ‚îú‚îÄ‚îÄ logger/                 # Logging setup
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/               # Training pipeline
‚îÇ   ‚îú‚îÄ‚îÄ prediction/             # FastAPI prediction pipeline
‚îÇ   ‚îú‚îÄ‚îÄ aws\_storage/            # AWS S3 interaction
‚îÇ   ‚îú‚îÄ‚îÄ utils/                  # Utility functions
‚îÇ   ‚îî‚îÄ‚îÄ constants/              # Constant values and thresholds
‚îÇ
‚îú‚îÄ‚îÄ templates/                  # HTML templates for the frontend
‚îú‚îÄ‚îÄ static/                     # Static files (CSS, JS)
‚îú‚îÄ‚îÄ notebook/                   # EDA & MongoDB integration notebooks
‚îú‚îÄ‚îÄ .github/workflows/          # GitHub Actions CI/CD setup
‚îú‚îÄ‚îÄ Dockerfile                  # Docker config for containerization
‚îú‚îÄ‚îÄ .dockerignore               # Files to ignore in Docker build
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ setup.py                    # Project packaging
‚îú‚îÄ‚îÄ pyproject.toml              # Python build system config
‚îú‚îÄ‚îÄ demo.py                     # Initial test script
‚îî‚îÄ‚îÄ app.py                      # FastAPI backend entry point

````

---

## üìå Step-by-Step Setup Instructions

### 1. üîß Project Initialization
```bash
python template.py             # Generate folder structure
````

### 2. üì¶ Packaging

Set up `setup.py` and `pyproject.toml` to install local modules.

> üìò Refer to `crashcourse.txt` to understand packaging.

---

### 3. üêç Create Virtual Environment

```bash
conda create -n laptop python=3.10 -y
conda activate laptop
pip install -r requirements.txt
pip list     # Confirm packages are installed
```

---

## üåê MongoDB Atlas Integration

1. Sign up on [MongoDB Atlas](https://www.mongodb.com/cloud/atlas)

2. Create a cluster (M0 Free Tier)

3. Create a user and allow IP `0.0.0.0/0`

4. Copy connection string for Python driver

5. Use the connection string in `.env` or environment variable:

   ```bash
   export MONGODB_URL="mongodb+srv://<user>:<password>@cluster.mongodb.net/db"
   ```

6. Load your dataset into MongoDB using the `mongoDB_demo.ipynb` notebook.

7. Verify data in the MongoDB collection (key-value format).

---

## üß∞ Logging & Exception Handling

* Create logger in `src/logger/logging.py` and test via `demo.py`
* Create custom exception class in `src/exception/exception.py`

---

## üìä Data Ingestion

* Define configs in `constants/`, `config_entity.py`, and `artifact_entity.py`
* Connect MongoDB and convert data to Pandas DataFrame
* Run Data Ingestion pipeline via `demo.py`

---

## ‚úÖ Data Validation & Transformation

* Validate dataset against schema (`schema.yaml`)
* Apply transformations: missing values, feature encoding, scaling
* Save transformation object using `estimator.py` for future reuse

---

## üß† Model Training

* Train regression model on transformed data
* Save trained model and metrics

---

## üß™ Model Evaluation (with AWS S3 Integration)

* Set up AWS account, IAM user, and configure credentials:

```bash
export AWS_ACCESS_KEY_ID="..."
export AWS_SECRET_ACCESS_KEY="..."
```

* Push models to S3 bucket: `my-model-mlopsproj`
* Track performance threshold to avoid downgrading model accuracy

---

## üöö Model Deployment (Model Pusher)

* Push best-performing model to production directory or S3
* Serve the model through FastAPI app (`app.py`)

---

## üåê Prediction API with FastAPI

* Frontend with HTML form (`templates/index.html`)
* Backend using FastAPI for form input ‚Üí prediction
* Hosted at: `http://<EC2-IP>:5000`

---

## üê≥ Docker Integration

* Create `Dockerfile` and `.dockerignore`
* Build Docker image:

```bash
docker build -t laptop-price-predictor .
```

---

## üîÅ CI/CD with GitHub Actions & AWS

### ‚úÖ Steps:

* Setup GitHub Actions workflow in `.github/workflows/aws.yaml`
* Build and push Docker image to AWS ECR
* Deploy image to EC2 using a self-hosted runner

### ‚öô GitHub Secrets to Set:

* `AWS_ACCESS_KEY_ID`
* `AWS_SECRET_ACCESS_KEY`
* `AWS_DEFAULT_REGION`
* `ECR_REPO`

---

## ‚òÅÔ∏è Deploy on EC2

1. Launch EC2 instance (Ubuntu)
2. Install Docker:

```bash
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker ubuntu
newgrp docker
```

3. Set up EC2 as a GitHub self-hosted runner
4. Expose port 5000 (security group inbound rule)

---

## ‚úÖ Model Training & Testing Endpoints

| Route      | Description                    |
| ---------- | ------------------------------ |
| `/`        | Home page with form            |
| `/predict` | Submit form and get prediction |
| `/train`   | Train and save new model       |

---

## üìà Technologies Used

| Domain               | Stack                                    |
| -------------------- | ---------------------------------------- |
| Language             | Python 3.10                              |
| Data                 | Pandas, NumPy                            |
| ML                   | scikit-learn                             |
| Logging & Exceptions | Custom logger & exception classes        |
| Database             | MongoDB Atlas                            |
| Backend              | FastAPI                                  |
| DevOps               | Docker, GitHub Actions, AWS EC2, S3, ECR |
| CI/CD                | GitHub Actions with self-hosted runner   |
| Deployment           | EC2 Ubuntu + Docker container            |

---

## üåü Highlighted Features

* ‚úÖ Real-world MLOps practices
* ‚úÖ MongoDB Atlas cloud database integration
* ‚úÖ Full modular architecture with reusable components
* ‚úÖ GitHub Actions for CI/CD pipeline
* ‚úÖ Containerized deployment via Docker
* ‚úÖ Fully deployed prediction system on AWS



---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------

## üì• How to Run This Project on Your System

Follow the steps below to run the **Laptop Price Predictor** project from scratch on your own machine:

---

### ‚úÖ 1. **Clone the Repository**

```bash
git clone https://github.com/Sourav5644/laptop-price-predictor
cd laptop-price-predictor
```

---

### ‚úÖ 2. **Create and Activate a Python Environment**

Using **conda**:

```bash
conda create -n laptop python=3.10 -y
conda activate laptop
```

Using **virtualenv** (alternative):

```bash
python -m venv laptop
source laptop/bin/activate  # On Windows: laptop\Scripts\activate
```

---

### ‚úÖ 3. **Install Dependencies**

```bash
pip install -r requirements.txt
```

---

### ‚úÖ 4. **Set MongoDB Connection URL**

You need a free MongoDB Atlas account.

* Go to [MongoDB Atlas](https://www.mongodb.com/cloud/atlas) and:

  * Create a free cluster
  * Add IP address: `0.0.0.0/0`
  * Create a user and get the connection string (driver: Python)
  * Replace `<username>` and `<password>` in your connection string

**Set the environment variable:**

**Linux/macOS (bash):**

```bash
export MONGODB_URL="your_connection_string"
```

**Windows (PowerShell):**

```powershell
$env:MONGODB_URL="your_connection_string"
```

---

### ‚úÖ 5. **Push Your Dataset to MongoDB**

1. Open `notebook/mongoDB_demo.ipynb`
2. Follow the code to upload your dataset to MongoDB Atlas
3. Check uploaded data in "Browse Collections"

---

### ‚úÖ 6. **Run the Full Training Pipeline**

```bash
python demo.py
```

This will perform:

* Data Ingestion
* Data Validation
* Data Transformation
* Model Training
* Model Evaluation
* Model Upload to AWS (if configured)

---

### ‚úÖ 7. **Launch the Web Application**

```bash
python app.py
```

Then open your browser and go to:

```
http://localhost:5000
```

* Fill the form and get laptop price predictions instantly.
* Use `/train` route to retrain the model manually.

---

### ‚úÖ 8. **Docker Deployment (Optional)**

To run with Docker:

```bash
docker build -t laptop-predictor .
docker run -p 5000:5000 laptop-predictor
```

Then visit: `http://localhost:5000`

---

### ‚úÖ 9. **CI/CD (Optional)**

CI/CD is pre-configured using:

* GitHub Actions
* AWS ECR, EC2, and S3

You can update your GitHub repo and it will auto-deploy to your EC2 instance.

---
---

## üôå Author

**Sourav Bhardwaj**
*Machine Learning | MLOps | Full Stack Projects Enthusiast*
[LinkedIn](www.linkedin.com/in/sourav-bhardwaj-88b9b7212) | [GitHub](https://github.com/Sourav5644/laptop-price-predictor)

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üìå Pro Tip for Recruiters

This project is **not just a notebook**. It reflects a **production-grade ML system**, showcasing:

* Software engineering practices
* Cloud deployment
* Real CI/CD pipeline
* Reusable ML components
* Full lifecycle from data to prediction

üëÄ Perfect for roles in ML Engineering, MLOps, or Full Stack Data Science!


